{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import KernelPCA, PCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN, SVMSMOTE\n",
    "import pandas as pd\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import make_scorer, roc_auc_score  # added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_normal_train = r'Saved_Embeddings/Normal/'\n",
    "base_path_abnormal_train = r'Saved_Embeddings/Abnormal/'\n",
    "base_path_normal_test = r'Saved_Embeddings/Normal_test/'\n",
    "base_path_abnormal_test = r'Saved_Embeddings/Abnormal_test/'\n",
    "use_dimensionality_reduction = False\n",
    "use_scaler = True\n",
    "use_age_gender_data = False\n",
    "use_oversampling = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_image_embeddings(base_path_normal, base_path_abnormal, age_gender_data):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    age_list = []\n",
    "    gender_list = []\n",
    "    normal_age_gender_data = age_gender_data[0]\n",
    "    abnormal_age_gender_data = age_gender_data[1]\n",
    "    normal_id_list = list(normal_age_gender_data['ID'])    \n",
    "    abnormal_id_list = list(abnormal_age_gender_data['ID'])\n",
    "    for k in os.listdir(base_path_normal):\n",
    "        age, gender = None, None\n",
    "        id_cleaned = int(''.join(filter(str.isdigit, k)))\n",
    "        if id_cleaned in normal_id_list:\n",
    "            _, gender, age = list(normal_age_gender_data.loc[normal_age_gender_data['ID'] == id_cleaned].values.ravel())\n",
    "        embeddings.append(np.load(base_path_normal + k))\n",
    "        age_list.append(age)\n",
    "        gender_list.append(gender)\n",
    "        labels.append(0)\n",
    "    for s in os.listdir(base_path_abnormal):\n",
    "        age, gender = None, None\n",
    "        id_cleaned = int(''.join(filter(str.isdigit, s)))\n",
    "        if id_cleaned in abnormal_id_list:\n",
    "            _, gender, age = list(\n",
    "                abnormal_age_gender_data.loc[abnormal_age_gender_data['ID'] == id_cleaned].values.ravel())\n",
    "        embeddings.append(np.load(base_path_abnormal + s))\n",
    "        labels.append(1)\n",
    "        age_list.append(age)\n",
    "        gender_list.append(gender)\n",
    "    return np.vstack(embeddings), np.array(labels), age_list, gender_list\n",
    "\n",
    "\n",
    "def load_all_data():\n",
    "    normal_train, abnormal_train, normal_test, abnormal_test = add_age_gender_data()\n",
    "\n",
    "    X_train, labels_train, age_list_train, gender_list_train = load_all_image_embeddings(base_path_normal_train,\n",
    "                                                                                         base_path_abnormal_train,\n",
    "                                                                                         (normal_train, abnormal_train))\n",
    "    X_test, labels_test, age_list_test, gender_list_test = load_all_image_embeddings(base_path_normal_test,\n",
    "                                                                                     base_path_abnormal_test,\n",
    "                                                                                     (normal_test, abnormal_test))\n",
    "    return X_train, labels_train, X_test, labels_test, age_list_train, age_list_test, gender_list_train, gender_list_test\n",
    "\n",
    "\n",
    "def do_scaling(X_train, X_test, method='standard'):\n",
    "    if method == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "#         print(\"Scaler used :- \", str(\"Standard Scaler\"))\n",
    "        return scaler.transform(X_train), scaler.transform(X_test)\n",
    "    elif method == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "#         print(\"Scaler used :- \", str(\"MinMax Scaler\"))\n",
    "        return scaler.transform(X_train), scaler.transform(X_test)\n",
    "    else:\n",
    "        return 'Not a valid method'\n",
    "\n",
    "\n",
    "def svm_model(X_train, Y_train, X_test, Y_test, params):\n",
    "    \n",
    "    svm_ = SVC(kernel=params['kernel'], gamma=params['gamma'], C= params['C'])\n",
    "    svm_.fit(X_train, Y_train)\n",
    "    pred_labels_test = svm_.predict(X_test)\n",
    "    pred_labels_train = svm_.predict(X_train)\n",
    "    print(pred_labels_test)\n",
    "    print(Y_test)\n",
    "    print('================================= Performance ==========================')\n",
    "    print(params)\n",
    "    print(\"Train Accuracy :- \", str(accuracy_score(Y_train, pred_labels_train)))\n",
    "    print(\"Test Accuracy :- \", str(accuracy_score(Y_test, pred_labels_test)))\n",
    "    #added\n",
    "    print('Test F1Score :- ', str(f1_score(Y_test, pred_labels_test, average='binary',labels=np.unique(pred_labels_test))))\n",
    "    print('Train F1Score :- ', str(f1_score(Y_train, pred_labels_train, average='binary',labels=np.unique(pred_labels_train))))\n",
    "    print('='*50)\n",
    "    return Y_test, pred_labels_test\n",
    "\n",
    "\n",
    "def grid_search_parameters(Data_X, Data_Y):\n",
    "    param_grid = {'C': [ 1., .1, .01, .001], # added 0.01\n",
    "                  'gamma': [100,10, 1, 0.1,],\n",
    "                  'kernel': ['rbf']}#['rbf', 'linear', 'poly',]} #removed 'sigmoid' and tried 'poly' - consistently performing poorly\n",
    "#     acc = make_scorer(custom_scorer, actual_scorer = accuracy_score)\n",
    "#     auc_score = make_scorer(custom_scorer, actual_scorer = roc_auc_score, needs_threshold=True) \n",
    "    fs = make_scorer(custom_scorer, actual_scorer = f1_score)\n",
    "#     gc = GridSearchCV(DecisionTreeClassifier(), param_grid=params, cv =cvv, \n",
    "#                   scoring={\"roc_auc\": auc_score, \"accuracy\": acc}, \n",
    "#                   refit=\"roc_auc\", n_jobs=-1, \n",
    "#                   return_train_score = True)\n",
    "#     grid = RandomizedSearchCV(SVC(), param_grid, verbose=3, scoring={\"roc_auc\": auc_score,}, refit = 'roc_auc')\n",
    "#     grid = RandomizedSearchCV(SVC(), param_grid, verbose=3, scoring=fs, refit = True)#{\"f1_score\": fs,}, refit = True, )\n",
    "    grid = GridSearchCV(SVC(), param_grid, verbose=3, scoring=fs)#{\"f1_score\": fs,}, refit = True, )\n",
    "#     print('Multimetric: ', grid.multimetric_)\n",
    "    grid.fit(Data_X, Data_Y)\n",
    "#     print('Best_params: ', grid.best_params_)\n",
    "    return grid.best_params_\n",
    "\n",
    "#Changed 'weighted' to 'macro'\n",
    "def calculate_all_acc_parameters(predicted_labels, y_true):\n",
    "#     print('labels') #-->prints out [0,1]\n",
    "#     print(np.unique(predicted_labels))\n",
    "    lbls = [0,1] #added and replaced 'np.unique(predicted_labels)' with 'lbls'\n",
    "    return accuracy_score(y_true, predicted_labels), \\\n",
    "            f1_score(y_true, predicted_labels, average='binary',labels=lbls), \\\n",
    "            recall_score(y_true,predicted_labels,average='binary', labels=lbls), \\\n",
    "            precision_score(y_true, predicted_labels, average='binary', labels=lbls)\n",
    "\n",
    "def ten_cross_validation(data_X, data_Y, params,model_name='svm', folds=10):\n",
    "    Accuracy, F1_score, Recall, Precision = [], [], [], []\n",
    "    kfold = KFold(folds, random_state=1, shuffle=True)\n",
    "    count = 1\n",
    "    Fold_Number = []\n",
    "    for train_index, test_index in kfold.split(data_X):\n",
    "        \n",
    "        X_train, X_test = data_X[train_index], data_X[test_index]\n",
    "        y_train, y_test = data_Y[train_index], data_Y[test_index]\n",
    "#         print(f'{count}th validation...')\n",
    "        svm_classifier = SVC().set_params(**params)\n",
    "        svm_classifier.fit(X_train, y_train)\n",
    "        accuracy, f1score, recall, precision = calculate_all_acc_parameters(svm_classifier.predict(X_test), y_test)\n",
    "        Accuracy.append(accuracy)\n",
    "        F1_score.append(f1score)\n",
    "        Recall.append(recall)\n",
    "        Precision.append(precision)\n",
    "        Fold_Number.append('Fold' + str(count))\n",
    "        \n",
    "        print(f'Fold{count}:\\t Accuracy: ', accuracy)\n",
    "        print('\\t F1 Score', f1score)\n",
    "        print('\\t Recall', recall)\n",
    "        print('\\t Precision', precision)\n",
    "        count = count + 1\n",
    "        \n",
    "    print('Accuracy', np.mean(Accuracy), end = '\\t')\n",
    "    print('F1 Score', np.mean(F1_score))\n",
    "    print('Recall', np.mean(Recall), end = '\\t')\n",
    "    print('Precision', np.mean(Precision))\n",
    "    return [Fold_Number, Accuracy, F1_score, Recall, Precision]\n",
    "\n",
    "\n",
    "def bbc_model(X_train, Y_train, X_test, Y_test):\n",
    "    bbc = BalancedBaggingClassifier(random_state=42)\n",
    "    bbc.fit(X_train, Y_train)\n",
    "    pred_labels_test = bbc.predict(X_test)\n",
    "    pred_labels_train = bbc.predict(X_train)\n",
    "    print(pred_labels_test)\n",
    "    print(Y_test)\n",
    "    print(\"Train Accuracy :- \", str(accuracy_score(Y_train, pred_labels_train)))\n",
    "    print(\"Test Accuracy :- \", str(accuracy_score(Y_test, pred_labels_test)))\n",
    "    return Y_test, pred_labels_test\n",
    "\n",
    "\n",
    "def do_dimensionality_reduction(X_train, X_test, Y_train, Y_test, method='kernelpca'):\n",
    "    if method == 'kernelpca':\n",
    "        earlier_dimension = X_train.shape[1]\n",
    "        kernelpca = KernelPCA()\n",
    "        kernelpca.fit(X_train)\n",
    "        X_train = kernelpca.transform(X_train)\n",
    "        X_test = kernelpca.transform(X_test)\n",
    "        print(\"Dimenion Reduced from :- \", str(earlier_dimension), \" to :- \", str(X_train.shape[1]), \" Using :- \",\n",
    "              str(method))\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    elif method == 'pca':\n",
    "        pca = PCA()\n",
    "        pca.fit(X_train)\n",
    "        earlier_dimension = X_train.shape[1]\n",
    "        X_train = pca.transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        print(\"Dimenion Reduced from :- \", str(earlier_dimension), \" to :- \", str(X_train.shape[1]), \" Using :- \",\n",
    "              str(method))\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    elif method == 'svd':\n",
    "        svd = TruncatedSVD()\n",
    "        svd.fit(X_train)\n",
    "        earlier_dimension = X_train.shape[1]\n",
    "        X_train = svd.transform(X_train)\n",
    "        X_test = svd.transform(X_test)\n",
    "        print(\"Dimenion Reduced from :- \", str(earlier_dimension), \" to :- \", str(X_train.shape[1]), \" Using :- \",\n",
    "              str(method))\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    elif method == 'tsne':\n",
    "        earlier_dimension = X_train.shape[1]\n",
    "        X = np.concatenate([X_train, X_test], axis=0)\n",
    "        Y = np.concatenate([Y_train, Y_test], axis=0)\n",
    "        X_embedded = TSNE(n_components=3).fit_transform(X)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_embedded, Y, test_size=.1)\n",
    "        print(\"Dimension Reduced from :- \", str(earlier_dimension), \" to :- \", str(X_train.shape[1]), \" Using :- \",\n",
    "              str(method))\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "\n",
    "def use_oversampling_method(X_train, Y_train, method='svmsmote'):\n",
    "    if method == 'smote':\n",
    "        oversample = SMOTE()\n",
    "        X_train, Y_train = oversample.fit_resample(X_train, Y_train)\n",
    "        print(\"oversampling used :- \", str(method))\n",
    "        return X_train, Y_train\n",
    "    elif method == 'randomsampler':\n",
    "        random = RandomOverSampler()\n",
    "        X_train, Y_train = random.fit_resample(X_train, Y_train)\n",
    "        print(\"oversampling used :- \", str(method))\n",
    "        return X_train, Y_train\n",
    "    elif method == 'adasyn':\n",
    "        adasyn = ADASYN()\n",
    "        X_train, Y_train = adasyn.fit_resample(X_train, Y_train)\n",
    "        print(\"oversampling used :- \", str(method))\n",
    "        return X_train, Y_train\n",
    "    elif method == \"svmsmote\":\n",
    "        svmsmote = SVMSMOTE()\n",
    "        X_train, Y_train = svmsmote.fit_resample(X_train, Y_train)\n",
    "        print(\"oversampling used :- \", str(method))\n",
    "        return X_train, Y_train\n",
    "    else:\n",
    "        print('Wrong Method')\n",
    "\n",
    "\n",
    "def add_age_gender_data():\n",
    "    normal_train = pd.read_excel('age and gender.xlsx', sheet_name=0)\n",
    "    abnormal_train = pd.read_excel('age and gender.xlsx', sheet_name=1)\n",
    "    normal_test = pd.read_excel('age and gender.xlsx', sheet_name=2)\n",
    "    abnormal_test = pd.read_excel('age and gender.xlsx', sheet_name=3)\n",
    "    return normal_train, abnormal_train, normal_test, abnormal_test\n",
    "\n",
    "\n",
    "def add_age_gender_to_data(data, agedata, gender_data):\n",
    "    temp_array = []\n",
    "    for index, k in enumerate(data):\n",
    "        temp_k = list(k) + [agedata[index], gender_data[index]]\n",
    "        temp_array.append(temp_k)\n",
    "    return np.array(temp_array)\n",
    "\n",
    "#added function\n",
    "def custom_scorer(y_true, y_pred, actual_scorer):\n",
    "    score = np.nan\n",
    "    try:\n",
    "        score = actual_scorer(y_true, y_pred)\n",
    "    except Exception: \n",
    "        pass\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, age_list_train, age_list_test, gender_list_train, gender_list_test = load_all_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(982, 2048)\n",
      "Using Oversampling with method = \"svmsmote\"\n",
      "oversampling used :-  svmsmote\n",
      "(1486, 2048)\n",
      "Using Scaler\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "================================= Performance ==========================\n",
      "{'kernel': 'linear', 'gamma': 0.0001, 'C': 100}\n",
      "Train Accuracy :-  1.0\n",
      "Test Accuracy :-  0.73\n",
      "Test F1Score :-  0.2285714285714286\n",
      "Train F1Score :-  1.0\n",
      "==================================================\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ......C=1.0, gamma=100, kernel=rbf;, score=0.050 total time=   3.4s\n",
      "[CV 2/5] END ......C=1.0, gamma=100, kernel=rbf;, score=0.066 total time=   3.3s\n",
      "[CV 3/5] END ......C=1.0, gamma=100, kernel=rbf;, score=0.066 total time=   3.2s\n",
      "[CV 4/5] END ......C=1.0, gamma=100, kernel=rbf;, score=0.033 total time=   3.6s\n",
      "[CV 5/5] END ......C=1.0, gamma=100, kernel=rbf;, score=0.050 total time=   3.2s\n",
      "[CV 1/5] END .......C=1.0, gamma=10, kernel=rbf;, score=0.156 total time=   3.2s\n",
      "[CV 2/5] END .......C=1.0, gamma=10, kernel=rbf;, score=0.186 total time=   3.2s\n",
      "[CV 3/5] END .......C=1.0, gamma=10, kernel=rbf;, score=0.171 total time=   3.2s\n",
      "[CV 4/5] END .......C=1.0, gamma=10, kernel=rbf;, score=0.081 total time=   3.3s\n",
      "[CV 5/5] END .......C=1.0, gamma=10, kernel=rbf;, score=0.081 total time=   3.2s\n",
      "[CV 1/5] END ........C=1.0, gamma=1, kernel=rbf;, score=0.416 total time=   3.2s\n",
      "[CV 2/5] END ........C=1.0, gamma=1, kernel=rbf;, score=0.329 total time=   3.2s\n",
      "[CV 3/5] END ........C=1.0, gamma=1, kernel=rbf;, score=0.350 total time=   3.2s\n",
      "[CV 4/5] END ........C=1.0, gamma=1, kernel=rbf;, score=0.252 total time=   3.2s\n",
      "[CV 5/5] END ........C=1.0, gamma=1, kernel=rbf;, score=0.226 total time=   3.6s\n",
      "[CV 1/5] END ......C=1.0, gamma=0.1, kernel=rbf;, score=0.696 total time=   3.4s\n",
      "[CV 2/5] END ......C=1.0, gamma=0.1, kernel=rbf;, score=0.655 total time=   3.1s\n",
      "[CV 3/5] END ......C=1.0, gamma=0.1, kernel=rbf;, score=0.696 total time=   3.3s\n",
      "[CV 4/5] END ......C=1.0, gamma=0.1, kernel=rbf;, score=0.587 total time=   3.2s\n",
      "[CV 5/5] END ......C=1.0, gamma=0.1, kernel=rbf;, score=0.604 total time=   3.3s\n",
      "[CV 1/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.000 total time=   3.4s\n",
      "[CV 2/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 3/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 4/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 5/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 1/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 2/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 3/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 4/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 5/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.000 total time=   3.5s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.000 total time=   3.4s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.000 total time=   3.4s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.4s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.3s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.3s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.7s\n",
      "[CV 1/5] END .....C=0.01, gamma=100, kernel=rbf;, score=0.000 total time=   3.3s\n",
      "[CV 2/5] END .....C=0.01, gamma=100, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 3/5] END .....C=0.01, gamma=100, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 4/5] END .....C=0.01, gamma=100, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 5/5] END .....C=0.01, gamma=100, kernel=rbf;, score=0.000 total time=   3.3s\n",
      "[CV 1/5] END ......C=0.01, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 2/5] END ......C=0.01, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 3/5] END ......C=0.01, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 4/5] END ......C=0.01, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 5/5] END ......C=0.01, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 1/5] END .......C=0.01, gamma=1, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 2/5] END .......C=0.01, gamma=1, kernel=rbf;, score=0.000 total time=   3.3s\n",
      "[CV 3/5] END .......C=0.01, gamma=1, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 4/5] END .......C=0.01, gamma=1, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 5/5] END .......C=0.01, gamma=1, kernel=rbf;, score=0.000 total time=   3.5s\n",
      "[CV 1/5] END .....C=0.01, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 2/5] END .....C=0.01, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.1s\n",
      "[CV 3/5] END .....C=0.01, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 4/5] END .....C=0.01, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.6s\n",
      "[CV 5/5] END .....C=0.01, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.5s\n",
      "[CV 1/5] END ....C=0.001, gamma=100, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 2/5] END ....C=0.001, gamma=100, kernel=rbf;, score=0.000 total time=   3.5s\n",
      "[CV 3/5] END ....C=0.001, gamma=100, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 4/5] END ....C=0.001, gamma=100, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 5/5] END ....C=0.001, gamma=100, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 1/5] END .....C=0.001, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 2/5] END .....C=0.001, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 3/5] END .....C=0.001, gamma=10, kernel=rbf;, score=0.000 total time=   3.3s\n",
      "[CV 4/5] END .....C=0.001, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 5/5] END .....C=0.001, gamma=10, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 1/5] END ......C=0.001, gamma=1, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 2/5] END ......C=0.001, gamma=1, kernel=rbf;, score=0.000 total time=   3.3s\n",
      "[CV 3/5] END ......C=0.001, gamma=1, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 4/5] END ......C=0.001, gamma=1, kernel=rbf;, score=0.000 total time=   3.4s\n",
      "[CV 5/5] END ......C=0.001, gamma=1, kernel=rbf;, score=0.000 total time=   3.4s\n",
      "[CV 1/5] END ....C=0.001, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 2/5] END ....C=0.001, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.1s\n",
      "[CV 3/5] END ....C=0.001, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "[CV 4/5] END ....C=0.001, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.3s\n",
      "[CV 5/5] END ....C=0.001, gamma=0.1, kernel=rbf;, score=0.000 total time=   3.2s\n",
      "================================= Validation ===================================\n",
      "Best parameters:  {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Fold1:\t Accuracy:  0.7421383647798742\n",
      "\t F1 Score 0.5684210526315789\n",
      "\t Recall 0.39705882352941174\n",
      "\t Precision 1.0\n",
      "Fold2:\t Accuracy:  0.7861635220125787\n",
      "\t F1 Score 0.6222222222222222\n",
      "\t Recall 0.45161290322580644\n",
      "\t Precision 1.0\n",
      "Fold3:\t Accuracy:  0.8553459119496856\n",
      "\t F1 Score 0.7578947368421053\n",
      "\t Recall 0.6101694915254238\n",
      "\t Precision 1.0\n",
      "Fold4:\t Accuracy:  0.8050314465408805\n",
      "\t F1 Score 0.6352941176470588\n",
      "\t Recall 0.46551724137931033\n",
      "\t Precision 1.0\n",
      "Fold5:\t Accuracy:  0.8050314465408805\n",
      "\t F1 Score 0.617283950617284\n",
      "\t Recall 0.44642857142857145\n",
      "\t Precision 1.0\n",
      "Fold6:\t Accuracy:  0.7924528301886793\n",
      "\t F1 Score 0.6373626373626373\n",
      "\t Recall 0.46774193548387094\n",
      "\t Precision 1.0\n",
      "Fold7:\t Accuracy:  0.8164556962025317\n",
      "\t F1 Score 0.6813186813186815\n",
      "\t Recall 0.5166666666666667\n",
      "\t Precision 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold8:\t Accuracy:  0.7911392405063291\n",
      "\t F1 Score 0.611764705882353\n",
      "\t Recall 0.4406779661016949\n",
      "\t Precision 1.0\n",
      "Fold9:\t Accuracy:  0.7974683544303798\n",
      "\t F1 Score 0.6363636363636364\n",
      "\t Recall 0.4666666666666667\n",
      "\t Precision 1.0\n",
      "Fold10:\t Accuracy:  0.7658227848101266\n",
      "\t F1 Score 0.6021505376344086\n",
      "\t Recall 0.4307692307692308\n",
      "\t Precision 1.0\n",
      "Accuracy 0.7957049597961945\tF1 Score 0.6370076278521967\n",
      "Recall 0.46933094967766537\tPrecision 1.0\n",
      "================================= Results ===================================\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "================================= Performance ==========================\n",
      "{'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Train Accuracy :-  1.0\n",
      "Test Accuracy :-  0.8\n",
      "Test F1Score :-  0.0\n",
      "Train F1Score :-  1.0\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "best_parameters = {'kernel': 'linear', 'gamma': 0.0001, 'C': 100}\n",
    "print(X_train.shape)\n",
    "\n",
    "if use_oversampling:\n",
    "    print('Using Oversampling with method = \"svmsmote\"')\n",
    "    X_train, Y_train = use_oversampling_method(X_train, Y_train, method='svmsmote')\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "if use_scaler:\n",
    "    print('Using Scaler')\n",
    "    X_train, X_test = do_scaling(X_train, X_test)\n",
    "\n",
    "if use_dimensionality_reduction:\n",
    "    print('Using Dimensionality Reduction, PCA')\n",
    "    X_train, X_test, Y_train, Y_test = do_dimensionality_reduction(X_train, X_test, Y_train, Y_test, method='svd')\n",
    "\n",
    "\n",
    "train_array = []\n",
    "\n",
    "if use_age_gender_data:\n",
    "    print('Using Age and Gender data')\n",
    "    X_train = add_age_gender_to_data(X_train, age_list_train, gender_list_train)\n",
    "    X_test = add_age_gender_to_data(X_test, age_list_test, gender_list_test)\n",
    "    print(\"After Age Data added shape of Train Data \", X_train.shape)\n",
    "    print(\"After Age Data added shape of Test Data \", X_test.shape)\n",
    "\n",
    "result =svm_model(X_train, Y_train, X_test, Y_test, best_parameters)\n",
    "# print(result)\n",
    "pd.DataFrame(result).to_csv('imbalanced_svm_Model.csv', index=False)\n",
    "\n",
    "best_parameters = grid_search_parameters(X_train, Y_train)\n",
    "X = np.concatenate([X_train, X_test], axis=0)\n",
    "Y = np.concatenate([Y_train, Y_test], axis=0)\n",
    "print('================================= Validation ===================================')\n",
    "print('Best parameters: ', best_parameters)\n",
    "pd.DataFrame(np.array(ten_cross_validation(X, Y,best_parameters, folds=10)).T,\n",
    "             columns=['Fold_Number', 'Accuracy', 'F1_Score', 'Recall', 'Precision']).to_csv('Results.csv', index=False)\n",
    "print('================================= Results ===================================')\n",
    "result_refined =svm_model(X_train, Y_train, X_test, Y_test, best_parameters)\n",
    "pd.DataFrame(result_refined).to_csv('imbalanced_svm_Model_refined.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.imshow(img_array, cmap='gray')\n",
    "# plt.show()\n",
    "# recall_score?\n",
    "f1_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomizedSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV().best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_refined[1] - result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomizedSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

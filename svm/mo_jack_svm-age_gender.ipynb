{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import KernelPCA, PCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN, SVMSMOTE\n",
    "import pandas as pd\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import make_scorer, roc_auc_score  # added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_normal_train = r'Saved_Embeddings/Normal/'\n",
    "base_path_abnormal_train = r'Saved_Embeddings/Abnormal/'\n",
    "base_path_normal_test = r'Saved_Embeddings/Normal_test/'\n",
    "base_path_abnormal_test = r'Saved_Embeddings/Abnormal_test/'\n",
    "use_dimensionality_reduction = False\n",
    "use_scaler = True\n",
    "use_age_gender_data = True\n",
    "use_oversampling = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_image_embeddings(base_path_normal, base_path_abnormal, age_gender_data):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    age_list = []\n",
    "    gender_list = []\n",
    "    normal_age_gender_data = age_gender_data[0]\n",
    "    abnormal_age_gender_data = age_gender_data[1]\n",
    "    normal_id_list = list(normal_age_gender_data['ID'])    \n",
    "    abnormal_id_list = list(abnormal_age_gender_data['ID'])\n",
    "    for k in os.listdir(base_path_normal):\n",
    "        age, gender = None, None\n",
    "        id_cleaned = int(''.join(filter(str.isdigit, k)))\n",
    "        if id_cleaned in normal_id_list:\n",
    "            _, gender, age = list(normal_age_gender_data.loc[normal_age_gender_data['ID'] == id_cleaned].values.ravel())\n",
    "        embeddings.append(np.load(base_path_normal + k))\n",
    "        age_list.append(age)\n",
    "        gender_list.append(gender)\n",
    "        labels.append(0)\n",
    "    for s in os.listdir(base_path_abnormal):\n",
    "        age, gender = None, None\n",
    "        id_cleaned = int(''.join(filter(str.isdigit, s)))\n",
    "        if id_cleaned in abnormal_id_list:\n",
    "            _, gender, age = list(\n",
    "                abnormal_age_gender_data.loc[abnormal_age_gender_data['ID'] == id_cleaned].values.ravel())\n",
    "        embeddings.append(np.load(base_path_abnormal + s))\n",
    "        labels.append(1)\n",
    "        age_list.append(age)\n",
    "        gender_list.append(gender)\n",
    "    return np.vstack(embeddings), np.array(labels), age_list, gender_list\n",
    "\n",
    "\n",
    "def load_all_data():\n",
    "    normal_train, abnormal_train, normal_test, abnormal_test = add_age_gender_data()\n",
    "\n",
    "    X_train, labels_train, age_list_train, gender_list_train = load_all_image_embeddings(base_path_normal_train,\n",
    "                                                                                         base_path_abnormal_train,\n",
    "                                                                                         (normal_train, abnormal_train))\n",
    "    X_test, labels_test, age_list_test, gender_list_test = load_all_image_embeddings(base_path_normal_test,\n",
    "                                                                                     base_path_abnormal_test,\n",
    "                                                                                     (normal_test, abnormal_test))\n",
    "    return X_train, labels_train, X_test, labels_test, age_list_train, age_list_test, gender_list_train, gender_list_test\n",
    "\n",
    "\n",
    "def do_scaling(X_train, X_test, method='standard'):\n",
    "    if method == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "#         print(\"Scaler used :- \", str(\"Standard Scaler\"))\n",
    "        return scaler.transform(X_train), scaler.transform(X_test)\n",
    "    elif method == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "#         print(\"Scaler used :- \", str(\"MinMax Scaler\"))\n",
    "        return scaler.transform(X_train), scaler.transform(X_test)\n",
    "    else:\n",
    "        return 'Not a valid method'\n",
    "\n",
    "\n",
    "def svm_model(X_train, Y_train, X_test, Y_test, params):\n",
    "    \n",
    "    svm_ = SVC(kernel=params['kernel'], gamma=params['gamma'], C= params['C'])\n",
    "    svm_.fit(X_train, Y_train)\n",
    "    pred_labels_test = svm_.predict(X_test)\n",
    "    pred_labels_train = svm_.predict(X_train)\n",
    "    print(pred_labels_test)\n",
    "    print(Y_test)\n",
    "    print('================================= Performance ==========================')\n",
    "    print(params)\n",
    "    print(\"Train Accuracy :- \", str(accuracy_score(Y_train, pred_labels_train)))\n",
    "    print(\"Test Accuracy :- \", str(accuracy_score(Y_test, pred_labels_test)))\n",
    "    #added\n",
    "    print('Test F1Score :- ', str(f1_score(Y_test, pred_labels_test, average='binary',labels=np.unique(pred_labels_test))))\n",
    "    print('Train F1Score :- ', str(f1_score(Y_train, pred_labels_train, average='binary',labels=np.unique(pred_labels_train))))\n",
    "    print('='*50)\n",
    "    return Y_test, pred_labels_test\n",
    "\n",
    "\n",
    "def grid_search_parameters(Data_X, Data_Y):\n",
    "    param_grid = {'C': [0.1, 1, 10, 0.01, .001], # added 0.01\n",
    "                  'gamma': [100,10, 1, 0.1, 0.01, 0.001,],\n",
    "                  'kernel': ['sigmoid']}#['rbf', 'linear', 'poly',]} #removed 'sigmoid' and tried 'poly' - consistently performing poorly\n",
    "#     acc = make_scorer(custom_scorer, actual_scorer = accuracy_score)\n",
    "#     auc_score = make_scorer(custom_scorer, actual_scorer = roc_auc_score, needs_threshold=True) \n",
    "    fs = make_scorer(custom_scorer, actual_scorer = f1_score)\n",
    "#     gc = GridSearchCV(DecisionTreeClassifier(), param_grid=params, cv =cvv, \n",
    "#                   scoring={\"roc_auc\": auc_score, \"accuracy\": acc}, \n",
    "#                   refit=\"roc_auc\", n_jobs=-1, \n",
    "#                   return_train_score = True)\n",
    "#     grid = RandomizedSearchCV(SVC(), param_grid, verbose=3, scoring={\"roc_auc\": auc_score,}, refit = 'roc_auc')\n",
    "    grid = RandomizedSearchCV(SVC(), param_grid, verbose=3, scoring=fs, refit = True)#{\"f1_score\": fs,}, refit = True, )\n",
    "    grid = GridSearchCV(SVC(), param_grid, verbose=3, scoring=fs)#{\"f1_score\": fs,}, refit = True, )\n",
    "#     print('Multimetric: ', grid.multimetric_)\n",
    "    grid.fit(Data_X, Data_Y)\n",
    "#     print('Best_params: ', grid.best_params_)\n",
    "    return grid.best_params_\n",
    "\n",
    "#Changed 'weighted' to 'macro'\n",
    "def calculate_all_acc_parameters(predicted_labels, y_true):\n",
    "#     print('labels') #-->prints out [0,1]\n",
    "#     print(np.unique(predicted_labels))\n",
    "    lbls = [0,1] #added and replaced 'np.unique(predicted_labels)' with 'lbls'\n",
    "    return accuracy_score(y_true, predicted_labels), \\\n",
    "            f1_score(y_true, predicted_labels, average='binary',labels=lbls), \\\n",
    "            recall_score(y_true,predicted_labels,average='binary', labels=lbls), \\\n",
    "            precision_score(y_true, predicted_labels, average='binary', labels=lbls)\n",
    "\n",
    "def ten_cross_validation(data_X, data_Y, params,model_name='svm', folds=10):\n",
    "    Accuracy, F1_score, Recall, Precision = [], [], [], []\n",
    "    kfold = KFold(folds, random_state=1, shuffle=True)\n",
    "    count = 1\n",
    "    Fold_Number = []\n",
    "    for train_index, test_index in kfold.split(data_X):\n",
    "        \n",
    "        X_train, X_test = data_X[train_index], data_X[test_index]\n",
    "        y_train, y_test = data_Y[train_index], data_Y[test_index]\n",
    "#         print(f'{count}th validation...')\n",
    "        svm_classifier = SVC().set_params(**params)\n",
    "        svm_classifier.fit(X_train, y_train)\n",
    "        accuracy, f1score, recall, precision = calculate_all_acc_parameters(svm_classifier.predict(X_test), y_test)\n",
    "        Accuracy.append(accuracy)\n",
    "        F1_score.append(f1score)\n",
    "        Recall.append(recall)\n",
    "        Precision.append(precision)\n",
    "        Fold_Number.append('Fold' + str(count))\n",
    "        \n",
    "        print(f'Fold{count}:\\t Accuracy: ', accuracy)\n",
    "        print('\\t F1 Score', f1score)\n",
    "        print('\\t Recall', recall)\n",
    "        print('\\t Precision', precision)\n",
    "        count = count + 1\n",
    "        \n",
    "    print('Accuracy', np.mean(Accuracy), end = '\\t')\n",
    "    print('F1 Score', np.mean(F1_score))\n",
    "    print('Recall', np.mean(Recall), end = '\\t')\n",
    "    print('Precision', np.mean(Precision))\n",
    "    return [Fold_Number, Accuracy, F1_score, Recall, Precision]\n",
    "\n",
    "\n",
    "def bbc_model(X_train, Y_train, X_test, Y_test):\n",
    "    bbc = BalancedBaggingClassifier(random_state=42)\n",
    "    bbc.fit(X_train, Y_train)\n",
    "    pred_labels_test = bbc.predict(X_test)\n",
    "    pred_labels_train = bbc.predict(X_train)\n",
    "    print(pred_labels_test)\n",
    "    print(Y_test)\n",
    "    print(\"Train Accuracy :- \", str(accuracy_score(Y_train, pred_labels_train)))\n",
    "    print(\"Test Accuracy :- \", str(accuracy_score(Y_test, pred_labels_test)))\n",
    "    return Y_test, pred_labels_test\n",
    "\n",
    "\n",
    "def do_dimensionality_reduction(X_train, X_test, Y_train, Y_test, method='kernelpca'):\n",
    "    if method == 'kernelpca':\n",
    "        earlier_dimension = X_train.shape[1]\n",
    "        kernelpca = KernelPCA()\n",
    "        kernelpca.fit(X_train)\n",
    "        X_train = kernelpca.transform(X_train)\n",
    "        X_test = kernelpca.transform(X_test)\n",
    "        print(\"Dimenion Reduced from :- \", str(earlier_dimension), \" to :- \", str(X_train.shape[1]), \" Using :- \",\n",
    "              str(method))\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    elif method == 'pca':\n",
    "        pca = PCA()\n",
    "        pca.fit(X_train)\n",
    "        earlier_dimension = X_train.shape[1]\n",
    "        X_train = pca.transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        print(\"Dimenion Reduced from :- \", str(earlier_dimension), \" to :- \", str(X_train.shape[1]), \" Using :- \",\n",
    "              str(method))\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    elif method == 'svd':\n",
    "        svd = TruncatedSVD()\n",
    "        svd.fit(X_train)\n",
    "        earlier_dimension = X_train.shape[1]\n",
    "        X_train = svd.transform(X_train)\n",
    "        X_test = svd.transform(X_test)\n",
    "        print(\"Dimenion Reduced from :- \", str(earlier_dimension), \" to :- \", str(X_train.shape[1]), \" Using :- \",\n",
    "              str(method))\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    elif method == 'tsne':\n",
    "        earlier_dimension = X_train.shape[1]\n",
    "        X = np.concatenate([X_train, X_test], axis=0)\n",
    "        Y = np.concatenate([Y_train, Y_test], axis=0)\n",
    "        X_embedded = TSNE(n_components=3).fit_transform(X)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_embedded, Y, test_size=.1)\n",
    "        print(\"Dimension Reduced from :- \", str(earlier_dimension), \" to :- \", str(X_train.shape[1]), \" Using :- \",\n",
    "              str(method))\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "\n",
    "def use_oversampling_method(X_train, Y_train, method='smote'):\n",
    "    if method == 'smote':\n",
    "        oversample = SMOTE()\n",
    "        X_train, Y_train = oversample.fit_resample(X_train, Y_train)\n",
    "        print(\"oversampling used :- \", str(method))\n",
    "        return X_train, Y_train\n",
    "    elif method == 'randomsampler':\n",
    "        random = RandomOverSampler()\n",
    "        X_train, Y_train = random.fit_resample(X_train, Y_train)\n",
    "        print(\"oversampling used :- \", str(method))\n",
    "        return X_train, Y_train\n",
    "    elif method == 'adasyn':\n",
    "        adasyn = ADASYN()\n",
    "        X_train, Y_train = adasyn.fit_resample(X_train, Y_train)\n",
    "        print(\"oversampling used :- \", str(method))\n",
    "        return X_train, Y_train\n",
    "    elif method == \"svmsmote\":\n",
    "        svmsmote = SVMSMOTE()\n",
    "        X_train, Y_train = svmsmote.fit_resample(X_train, Y_train)\n",
    "        print(\"oversampling used :- \", str(method))\n",
    "        return X_train, Y_train\n",
    "    else:\n",
    "        print('Wrong Method')\n",
    "\n",
    "\n",
    "def add_age_gender_data():\n",
    "    normal_train = pd.read_excel('age and gender.xlsx', sheet_name=0)\n",
    "    abnormal_train = pd.read_excel('age and gender.xlsx', sheet_name=1)\n",
    "    normal_test = pd.read_excel('age and gender.xlsx', sheet_name=2)\n",
    "    abnormal_test = pd.read_excel('age and gender.xlsx', sheet_name=3)\n",
    "    return normal_train, abnormal_train, normal_test, abnormal_test\n",
    "\n",
    "\n",
    "def add_age_gender_to_data(data, agedata, gender_data):\n",
    "    temp_array = []\n",
    "    for index, k in enumerate(data):\n",
    "        temp_k = list(k) + [agedata[index], gender_data[index]]\n",
    "        temp_array.append(temp_k)\n",
    "    return np.array(temp_array)\n",
    "\n",
    "#added function\n",
    "def custom_scorer(y_true, y_pred, actual_scorer):\n",
    "    score = np.nan\n",
    "    try:\n",
    "        score = actual_scorer(y_true, y_pred)\n",
    "    except Exception: \n",
    "        pass\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, age_list_train, age_list_test, gender_list_train, gender_list_test = load_all_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(982, 2048)\n",
      "Using Oversampling with method = \"svmsmote\"\n",
      "oversampling used :-  svmsmote\n",
      "(1512, 2048)\n",
      "Using Scaler\n",
      "Using Age and Gender data\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-094bde8ce44f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_age_gender_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using Age and Gender data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_age_gender_to_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage_list_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgender_list_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_age_gender_to_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage_list_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgender_list_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"After Age Data added shape of Train Data \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e0139b4b3df5>\u001b[0m in \u001b[0;36madd_age_gender_to_data\u001b[1;34m(data, agedata, gender_data)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[0mtemp_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mtemp_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0magedata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgender_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[0mtemp_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "best_parameters = {'kernel': 'linear', 'gamma': 1, 'C': 1}\n",
    "print(X_train.shape)\n",
    "\n",
    "if use_oversampling:\n",
    "    print('Using Oversampling with method = \"svmsmote\"')\n",
    "    X_train, Y_train = use_oversampling_method(X_train, Y_train, method='svmsmote')\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "if use_scaler:\n",
    "    print('Using Scaler')\n",
    "    X_train, X_test = do_scaling(X_train, X_test)\n",
    "\n",
    "if use_dimensionality_reduction:\n",
    "    print('Using Dimensionality Reduction, PCA')\n",
    "    X_train, X_test, Y_train, Y_test = do_dimensionality_reduction(X_train, X_test, Y_train, Y_test, method='pca')\n",
    "\n",
    "\n",
    "train_array = []\n",
    "\n",
    "if use_age_gender_data:\n",
    "    print('Using Age and Gender data')\n",
    "    X_train = add_age_gender_to_data(X_train, age_list_train, gender_list_train)\n",
    "    X_test = add_age_gender_to_data(X_test, age_list_test, gender_list_test)\n",
    "    print(\"After Age Data added shape of Train Data \", X_train.shape)\n",
    "    print(\"After Age Data added shape of Test Data \", X_test.shape)\n",
    "\n",
    "result =svm_model(X_train, Y_train, X_test, Y_test, best_parameters)\n",
    "# print(result)\n",
    "pd.DataFrame(result).to_csv('imbalanced_svm_Model.csv', index=False)\n",
    "\n",
    "best_parameters = grid_search_parameters(X_train, Y_train)\n",
    "X = np.concatenate([X_train, X_test], axis=0)\n",
    "Y = np.concatenate([Y_train, Y_test], axis=0)\n",
    "print('================================= Validation ===================================')\n",
    "print('Best parameters: ', best_parameters)\n",
    "pd.DataFrame(np.array(ten_cross_validation(X, Y,best_parameters, folds=10)).T,\n",
    "             columns=['Fold_Number', 'Accuracy', 'F1_Score', 'Recall', 'Precision']).to_csv('Results.csv', index=False)\n",
    "print('================================= Results ===================================')\n",
    "result_refined =svm_model(X_train, Y_train, X_test, Y_test, best_parameters)\n",
    "pd.DataFrame(result_refined).to_csv('imbalanced_svm_Model_refined.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.imshow(img_array, cmap='gray')\n",
    "# plt.show()\n",
    "# recall_score?\n",
    "f1_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomizedSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV().best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,\n",
       "        0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0, -1,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  1,  0, -1,  0,  0,  0, -1,  0,  0,\n",
       "        0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_refined[1] - result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

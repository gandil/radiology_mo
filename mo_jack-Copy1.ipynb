{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0d579b",
   "metadata": {},
   "source": [
    "# Determining if there is a significant difference between models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3806cd",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5d7db0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ecb19",
   "metadata": {},
   "source": [
    "## 2. Load Actual and Predicted data for each model and calculate confusion matrix for each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c64352",
   "metadata": {},
   "source": [
    "### 2a. SVMSmote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "148b1847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 16]\n",
      " [11 69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.20      0.23        20\n",
      "           0       0.81      0.86      0.84        80\n",
      "\n",
      "    accuracy                           0.73       100\n",
      "   macro avg       0.54      0.53      0.53       100\n",
      "weighted avg       0.70      0.73      0.71       100\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4, 16, 11, 69], dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmsmote_df = pd.read_csv('svmsmote_standard_Model.csv')\n",
    "y_act = list(svmsmote_df.Acc)\n",
    "y_pred = list(svmsmote_df.Pred)\n",
    "conf_svmsmote = metrics.confusion_matrix(y_act, y_pred, labels = [1,0])\n",
    "print(conf_svmsmote)\n",
    "print(metrics.classification_report(y_act, y_pred, labels = [1,0]))\n",
    "\n",
    "conf_svmsmote.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e543880",
   "metadata": {},
   "source": [
    "### 2b. Randomsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aa875fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 15]\n",
      " [ 9 71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.25      0.29        20\n",
      "           0       0.83      0.89      0.86        80\n",
      "\n",
      "    accuracy                           0.76       100\n",
      "   macro avg       0.59      0.57      0.57       100\n",
      "weighted avg       0.73      0.76      0.74       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "randomsampler_df = pd.read_csv('randomsampler_standard_Model.csv')\n",
    "y_act = list(randomsampler_df.Acc)\n",
    "y_pred = list(randomsampler_df.pred)\n",
    "conf_rand = metrics.confusion_matrix(y_act, y_pred, labels = [1,0])\n",
    "print(conf_rand)\n",
    "print(metrics.classification_report(y_act, y_pred, labels = [1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950100e5",
   "metadata": {},
   "source": [
    "### 2c. Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6236fafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 16]\n",
      " [ 9 71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.20      0.24        20\n",
      "           0       0.82      0.89      0.85        80\n",
      "\n",
      "    accuracy                           0.75       100\n",
      "   macro avg       0.56      0.54      0.55       100\n",
      "weighted avg       0.71      0.75      0.73       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote_df = pd.read_csv('Smote_standard_Model.csv')\n",
    "y_act = list(smote_df.Acc)\n",
    "y_pred = list(smote_df.pred)\n",
    "conf_smote = metrics.confusion_matrix(y_act, y_pred, labels = [1,0])\n",
    "print(conf_smote)\n",
    "print(metrics.classification_report(y_act, y_pred, labels = [1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3815a13",
   "metadata": {},
   "source": [
    "### 2d. Adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ae34b8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 16]\n",
      " [ 9 71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.20      0.24        20\n",
      "           0       0.82      0.89      0.85        80\n",
      "\n",
      "    accuracy                           0.75       100\n",
      "   macro avg       0.56      0.54      0.55       100\n",
      "weighted avg       0.71      0.75      0.73       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adasyn_df = pd.read_csv('adasyn_standard_Model.csv')\n",
    "y_act = list(adasyn_df.Acc)\n",
    "y_pred = list(adasyn_df.Pred)\n",
    "conf_adasyn = metrics.confusion_matrix(y_act, y_pred, labels = [1,0])\n",
    "print(conf_adasyn)\n",
    "print(metrics.classification_report(y_act, y_pred, labels = [1,0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8ae49",
   "metadata": {},
   "source": [
    "## 3. Convert confusion matrices above into a contingency matrix (stored as DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c8f45413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svmsmote</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smote</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adasyn</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TP  FN  FP\n",
       "svmsmote   4  16  11\n",
       "random     5  15   9\n",
       "smote      4  16   9\n",
       "adasyn     4  16   9"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([conf_svmsmote.flatten(), conf_rand.flatten(), conf_smote.flatten(), conf_adasyn.flatten()])\n",
    "contingency = pd.DataFrame(np.array([conf_svmsmote.flatten(), conf_rand.flatten(), conf_smote.flatten(), conf_smote.flatten()]))\n",
    "contingency.index = ['svmsmote', 'random', 'smote', 'adasyn']\n",
    "contingency.columns = ['TP', 'FN', 'FP', 'TN'] #TP = True +ve, FN = False -ve, FP = False +ve, TN = True -ve\n",
    "contingency= contingency.iloc[:,:3] #exclude TN because it is a function of TP,FN and FP\n",
    "contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "65b070f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency.to_excel('cont1.xlsx') #incase you need to store and test the process by using excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2845f4",
   "metadata": {},
   "source": [
    "## 4. Calculate Chi-Square parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0c8e7b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4339755143710005\n",
      "0.9985516783166436\n",
      "6\n",
      "[[ 4.46610169 16.55084746  9.98305085]\n",
      " [ 4.1779661  15.48305085  9.33898305]\n",
      " [ 4.1779661  15.48305085  9.33898305]\n",
      " [ 4.1779661  15.48305085  9.33898305]]\n"
     ]
    }
   ],
   "source": [
    "stat, p, dof, expected = chi2_contingency(contingency)\n",
    "print(stat)\n",
    "print(p)\n",
    "print(dof)\n",
    "print(expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a6fbe",
   "metadata": {},
   "source": [
    "## 5. Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "68323a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical Value = 12.591587243743977\n",
      "Fail to reject Ho, independent\n",
      "Significance = 0.05, p-value = 0.9985516783166436\n",
      "Fail to reject Ho, independent\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Null Hypothesis (Ho): Performance  and type of model are independent\n",
    "Alternative Hypothesis (H1): Performance and type of model are not independent\n",
    "'''\n",
    "\n",
    "\n",
    "#set alpha = 0.05 i.e probability = 0.95 (left side)\n",
    "alpha = 0.05\n",
    "prob = 1-alpha \n",
    "#critival value = cv\n",
    "\n",
    "#By using test statistic X2\n",
    "cv = chi2.ppf(prob, dof)\n",
    "print(f'Critical Value = {cv}')\n",
    "if abs(stat) >= cv:\n",
    "    print('Reject Ho, dependent')\n",
    "else:\n",
    "    print('Fail to reject Ho, independent')\n",
    "    \n",
    "#By using probability distribution (p)\n",
    "print(f'Significance = {alpha}, p-value = {p}')\n",
    "if p < alpha:\n",
    "    print('Reject Ho, dependent')\n",
    "else:\n",
    "    print('Fail to reject Ho, independent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8512316e",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "#### The results mean that performance is independent of the model used\n",
    "#### i.e. difference between the given models are not strong enough to impact the results\n",
    "#### However:\n",
    "#### This does not say whether the models are performing well or otherwise,  it only means that models have similar level of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602dbdee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

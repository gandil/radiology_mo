{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import KernelPCA, PCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN, SVMSMOTE\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, make_scorer, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare variables\n",
    "base_path_normal_train = 'Saved_Embeddings/Normal/'\n",
    "base_path_abnormal_train = 'Saved_Embeddings/Abnormal/'\n",
    "base_path_normal_test = 'Saved_Embeddings/Normal_test/'\n",
    "base_path_abnormal_test = 'Saved_Embeddings/Abnormal_test/'\n",
    "use_dimensionality_reduction = True\n",
    "use_scaler = True\n",
    "use_age_gender_data = False\n",
    "use_oversampling = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Loading and scaling\n",
    "\n",
    "def load_all_image_embeddings(base_path_normal, base_path_abnormal, age_gender_data):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    age_list = []\n",
    "    gender_list = []\n",
    "    normal_age_gender_data = age_gender_data[0]\n",
    "    abnormal_age_gender_data = age_gender_data[1]\n",
    "    normal_id_list = list(normal_age_gender_data['ID'])\n",
    "    abnormal_id_list = list(abnormal_age_gender_data['ID'])\n",
    "    for k in os.listdir(base_path_normal):\n",
    "        age, gender = None, None\n",
    "        id_cleaned = int(''.join(filter(str.isdigit, k)))\n",
    "        if id_cleaned in normal_id_list:\n",
    "            _, gender, age = list(normal_age_gender_data.loc[normal_age_gender_data['ID'] == id_cleaned].values.ravel())\n",
    "        embeddings.append(np.load(base_path_normal + k))\n",
    "        age_list.append(age)\n",
    "        gender_list.append(gender)\n",
    "        labels.append(0)\n",
    "    for s in os.listdir(base_path_abnormal):\n",
    "        age, gender = None, None\n",
    "        id_cleaned = int(''.join(filter(str.isdigit, s)))\n",
    "        if id_cleaned in abnormal_id_list:\n",
    "            _, gender, age = list(\n",
    "                abnormal_age_gender_data.loc[abnormal_age_gender_data['ID'] == id_cleaned].values.ravel())\n",
    "        embeddings.append(np.load(base_path_abnormal + s))\n",
    "        labels.append(1)\n",
    "        age_list.append(age)\n",
    "        gender_list.append(gender)\n",
    "    return np.vstack(embeddings), np.array(labels), age_list, gender_list\n",
    "\n",
    "\n",
    "def load_all_data():\n",
    "    normal_train, abnormal_train, normal_test, abnormal_test = add_age_gender_data()\n",
    "\n",
    "    X_train, labels_train, age_list_train, gender_list_train = load_all_image_embeddings(base_path_normal_train,\n",
    "                                                                                         base_path_abnormal_train,\n",
    "                                                                                         (normal_train, abnormal_train))\n",
    "    X_test, labels_test, age_list_test, gender_list_test = load_all_image_embeddings(base_path_normal_test,\n",
    "                                                                                     base_path_abnormal_test,\n",
    "                                                                                     (normal_test, abnormal_test))\n",
    "    #return X_train, labels_train, X_test, labels_test, age_list_train, age_list_test, gender_list_train, gender_list_test\n",
    "    return X_train, labels_train, X_test, labels_test\n",
    "\n",
    "def add_age_gender_data():\n",
    "    normal_train = pd.read_excel('age and gender.xlsx', sheet_name=0)\n",
    "    abnormal_train = pd.read_excel('age and gender.xlsx', sheet_name=1)\n",
    "    normal_test = pd.read_excel('age and gender.xlsx', sheet_name=2)\n",
    "    abnormal_test = pd.read_excel('age and gender.xlsx', sheet_name=3)\n",
    "    return normal_train, abnormal_train, normal_test, abnormal_test\n",
    "\n",
    "\n",
    "def add_age_gender_to_data(data, agedata, gender_data):\n",
    "    temp_array = []\n",
    "    for index, k in enumerate(data):\n",
    "        temp_k = list(k) + [agedata[index], gender_data[index]]\n",
    "        temp_array.append(temp_k)\n",
    "    return np.array(temp_array)\n",
    "\n",
    "\n",
    "def do_scaling(X_train, X_test, method='standard'):\n",
    "    if method == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        print(\"Scaler used :- \", str(\"Standard Scaler\"))\n",
    "        return scaler.transform(X_train), scaler.transform(X_test)\n",
    "    elif method == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "        print(\"Scaler used :- \", str(\"MinMax Scaler\"))\n",
    "        return scaler.transform(X_train), scaler.transform(X_test)\n",
    "    else:\n",
    "        return 'Not a valid method'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "def cm_display(arr1, arr2, title):\n",
    "    \n",
    "    # imb_svm_df\n",
    "    cm = confusion_matrix(  arr1, arr2)\n",
    "    plt.figure(figsize = (5,5))\n",
    "    ConfusionMatrixDisplay(cm).plot(cmap = 'viridis')\n",
    "    plt.title = title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "\n",
    "def use_oversampling_method(X_train, Y_train, method='adasyn'):\n",
    "    if method == 'smote':\n",
    "        oversample = SMOTE()\n",
    "        X_train, Y_train = oversample.fit_resample(X_train, Y_train)\n",
    "        print(\"oversampling used :- \", str(method))\n",
    "        return X_train, Y_train\n",
    "    elif method == 'randomsampler': #vulnerable to overfitting\n",
    "        random = RandomOverSampler()\n",
    "        X_train, Y_train = random.fit_resample(X_train, Y_train)\n",
    "        print(\"oversampling used :- \", str(method))\n",
    "        return X_train, Y_train\n",
    "    elif method == 'adasyn':\n",
    "        adasyn = ADASYN()\n",
    "        X_train, Y_train = adasyn.fit_resample(X_train, Y_train)\n",
    "        print(\"oversampling used :- \", str(method))\n",
    "        return X_train, Y_train\n",
    "    elif method == \"svmsmote\":\n",
    "        svmsmote = SVMSMOTE()\n",
    "        X_train, Y_train = svmsmote.fit_resample(X_train, Y_train)\n",
    "        print(\"oversampling used :- \", str(method))\n",
    "        return X_train, Y_train\n",
    "    else:\n",
    "        print('Wrong Method')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_reduction(X_train, X_test, Y_train, Y_test, rand):\n",
    "    earlier_dimension = X_train.shape[1]\n",
    "    X = np.concatenate([X_train, X_test], axis=0)\n",
    "    Y = np.concatenate([Y_train, Y_test], axis=0)\n",
    "    X_embedded = TSNE(n_components=3, init = 'random', random_state = rand).fit_transform(X) #random_state = 42, n_components=3\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_embedded, Y, test_size=.1)\n",
    "#     print(\"Dimension Reduced from :- \", str(earlier_dimension), \" to :- \", str(X_train.shape[1]), \" Using TSNE \"\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "def svm_model(X_train, Y_train, X_test, Y_test, params, rand ):\n",
    "    print(f'===================== Running the SVM model  with {params}')\n",
    "#     svm_classifier = SVC(kernel=params['kernel'], gamma = params['gamma'], C = params['C'])\n",
    "    svm_classifier = SVC().set_params(**params)\n",
    "    svm_classifier.fit(X_train, Y_train)\n",
    "    pred_labels_test= svm_classifier.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(Y_test, pred_labels_test).ravel()\n",
    "    precision = tp / (tp + fp) #should be fp instead of tn\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    if (precision > 0 ) and (recall > 0):\n",
    "        \n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        print('----------------', f1, recall, precision, sep = '\\t')\n",
    "    else:\n",
    "        print('----',  precision, recall, sep = '\\t')\n",
    "\n",
    "    accuracy, f1score, recall, precision=calculate_all_acc_parameters(pred_labels_test, Y_test)\n",
    "    print(accuracy,f1score,recall,precision)\n",
    "    plt_title = f'Random State = {rand}'\n",
    "    cm_display(Y_test, pred_labels_test, plt_title)\n",
    "    \n",
    "    return (Y_test, pred_labels_test), f1score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, Y_train, X_test, Y_test = load_all_data()\n",
    "# X_train, Y_train, X_test, Y_test, age_list_train, age_list_test, gender_list_train, gender_list_test = load_all_data()\n",
    "\n",
    "print('Data size.................................')\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print('...............................................')\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "oversampling was here. Which should go first, oversampling or dimensionality reduction?\n",
    "'''\n",
    "if use_oversampling:\n",
    "    X_train, Y_train = use_oversampling_method(X_train, Y_train, method='smote')\n",
    "\n",
    "print('Data size after oversampling ..................')\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print('...............................................')\n",
    "\n",
    "\n",
    "if use_scaler:\n",
    "    X_train, X_test = do_scaling(X_train, X_test, method = 'minmax')\n",
    "\n",
    "# best_ps={'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
    "\n",
    "best_ps={'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
    "\n",
    "performance = []\n",
    "for i in range(50):\n",
    "    X_train, X_test, Y_train, Y_test = tsne_reduction(X_train, X_test, Y_train, Y_test, i)\n",
    "    print(f'\\n{i}. Data size after TSNE: .........................')\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    print('...............................................')\n",
    "    df_train = pd.DataFrame(X_train)\n",
    "    df_train.columns = ['x', 'y', 'z']\n",
    "    df_train['status'] = Y_train\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    ax = plt.axes(projection = '3d')\n",
    "\n",
    "    x = df_train.x\n",
    "    y = df_train.y\n",
    "    z = df_train.z\n",
    "\n",
    "    ax.scatter(x,y,z, zdir = 'z',c = df_train.status, cmap = 'viridis')\n",
    "    result,f1score =svm_model(X_train, Y_train, X_test, Y_test, best_ps, i)\n",
    "    performance.append([i,f1score])\n",
    "    pd.DataFrame(result).to_csv(f'testing\\Testing_Rand_State_{i}.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = pd.DataFrame(performance)\n",
    "performance_df.columns = ['Random_state', 'F1Score']\n",
    "plt.figure()\n",
    "plt.plot(performance_df.Random_state, performance_df.F1Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
